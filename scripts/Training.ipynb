{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLDMdwY40pyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Prerequisites\n",
        "\n",
        "  1.Add the  dataset .csv files on the google drive as it will be mounted in the notebook'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4K5mB5oFHcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP5BO3dK0sgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "13039d62-5dcf-4afb-a51d-edd7affa66ad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuXRSQDY1ek2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_data = pd.read_csv(\"/content/drive/My Drive/Total_input_data_shuffle(X).csv\")\n",
        "Y_data = pd.read_csv(\"/content/drive/My Drive/Total_output_data_shuffle(Y).csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Frmk0FMX132J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "4bff93dd-340b-42ae-c3ee-472e77caf10b"
      },
      "source": [
        "print(\"shape of input: {}\".format(X_data.shape))\n",
        "X_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of input: (12288, 660)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>620</th>\n",
              "      <th>621</th>\n",
              "      <th>622</th>\n",
              "      <th>623</th>\n",
              "      <th>624</th>\n",
              "      <th>625</th>\n",
              "      <th>626</th>\n",
              "      <th>627</th>\n",
              "      <th>628</th>\n",
              "      <th>629</th>\n",
              "      <th>630</th>\n",
              "      <th>631</th>\n",
              "      <th>632</th>\n",
              "      <th>633</th>\n",
              "      <th>634</th>\n",
              "      <th>635</th>\n",
              "      <th>636</th>\n",
              "      <th>637</th>\n",
              "      <th>638</th>\n",
              "      <th>639</th>\n",
              "      <th>640</th>\n",
              "      <th>641</th>\n",
              "      <th>642</th>\n",
              "      <th>643</th>\n",
              "      <th>644</th>\n",
              "      <th>645</th>\n",
              "      <th>646</th>\n",
              "      <th>647</th>\n",
              "      <th>648</th>\n",
              "      <th>649</th>\n",
              "      <th>650</th>\n",
              "      <th>651</th>\n",
              "      <th>652</th>\n",
              "      <th>653</th>\n",
              "      <th>654</th>\n",
              "      <th>655</th>\n",
              "      <th>656</th>\n",
              "      <th>657</th>\n",
              "      <th>658</th>\n",
              "      <th>659</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.129412</td>\n",
              "      <td>0.082353</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.023529</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.580392</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.227451</td>\n",
              "      <td>0.219608</td>\n",
              "      <td>0.760784</td>\n",
              "      <td>0.050980</td>\n",
              "      <td>0.074510</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.152941</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.549020</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.403922</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.423529</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.984314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.576471</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>0.141176</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.231373</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.964706</td>\n",
              "      <td>0.356863</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.568627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.109804</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.219608</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.611765</td>\n",
              "      <td>0.196078</td>\n",
              "      <td>0.713725</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.490196</td>\n",
              "      <td>0.227451</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.407843</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.415686</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.345098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.474510</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.215686</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.043137</td>\n",
              "      <td>0.278431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.109804</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.792157</td>\n",
              "      <td>0.592157</td>\n",
              "      <td>0.505882</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.145098</td>\n",
              "      <td>0.227451</td>\n",
              "      <td>0.745098</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.074510</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.152941</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.568627</td>\n",
              "      <td>0.815686</td>\n",
              "      <td>0.474510</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.168627</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.023529</td>\n",
              "      <td>0.101961</td>\n",
              "      <td>0.792157</td>\n",
              "      <td>0.317647</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.878431</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.141176</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>0.549020</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.219608</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.031373</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>0.262745</td>\n",
              "      <td>0.611765</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.482353</td>\n",
              "      <td>0.207843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.396078</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.431373</td>\n",
              "      <td>0.074510</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.482353</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.207843</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.062745</td>\n",
              "      <td>0.027451</td>\n",
              "      <td>0.290196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.094118</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.043137</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.913725</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.458824</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.062745</td>\n",
              "      <td>0.145098</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.074510</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.145098</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.552941</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.231373</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.180392</td>\n",
              "      <td>0.337255</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.796078</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.725490</td>\n",
              "      <td>0.109804</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.596078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090196</td>\n",
              "      <td>0.596078</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>0.325490</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.211765</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>0.850980</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.188235</td>\n",
              "      <td>0.168627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.537255</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.427451</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.274510</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.462745</td>\n",
              "      <td>0.843137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.215686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188235</td>\n",
              "      <td>0.231373</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>0.031373</td>\n",
              "      <td>0.262745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.062745</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.031373</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.576471</td>\n",
              "      <td>0.525490</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.65098</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560784</td>\n",
              "      <td>0.847059</td>\n",
              "      <td>0.407843</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.156863</td>\n",
              "      <td>0.443137</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.972549</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.576471</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.141176</td>\n",
              "      <td>0.760784</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.952941</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.227451</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.701961</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.219608</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>0.650980</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.980392</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.537255</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.450980</td>\n",
              "      <td>0.082353</td>\n",
              "      <td>0.545098</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>0.090196</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.482353</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.231373</td>\n",
              "      <td>0.890196</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.043137</td>\n",
              "      <td>0.239216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.062745</td>\n",
              "      <td>0.082353</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.792157</td>\n",
              "      <td>0.596078</td>\n",
              "      <td>0.541176</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.172549</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.745098</td>\n",
              "      <td>0.172549</td>\n",
              "      <td>0.074510</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.65098</td>\n",
              "      <td>0.325490</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.580392</td>\n",
              "      <td>0.854902</td>\n",
              "      <td>0.490196</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.023529</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.188235</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.101961</td>\n",
              "      <td>0.792157</td>\n",
              "      <td>0.325490</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.262745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.262745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196078</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.023529</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.227451</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.835294</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.980392</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.537255</td>\n",
              "      <td>0.196078</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560784</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.556863</td>\n",
              "      <td>0.403922</td>\n",
              "      <td>0.082353</td>\n",
              "      <td>0.360784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.494118</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.890196</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.196078</td>\n",
              "      <td>0.062745</td>\n",
              "      <td>0.027451</td>\n",
              "      <td>0.258824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 660 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2         3  ...       656       657       658       659\n",
              "0  1.0  0.0  1.0  0.129412  ...  0.239216  0.098039  0.043137  0.278431\n",
              "1  1.0  0.0  1.0  0.109804  ...  0.254902  0.062745  0.027451  0.290196\n",
              "2  1.0  0.0  1.0  0.094118  ...  0.231373  0.035294  0.031373  0.262745\n",
              "3  1.0  0.0  1.0  0.078431  ...  0.200000  0.098039  0.043137  0.239216\n",
              "4  1.0  0.0  1.0  0.062745  ...  0.196078  0.062745  0.027451  0.258824\n",
              "\n",
              "[5 rows x 660 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbkQBGNB1_Pr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "49071db0-0876-4910-b8c7-466886e4f828"
      },
      "source": [
        "Y_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>620</th>\n",
              "      <th>621</th>\n",
              "      <th>622</th>\n",
              "      <th>623</th>\n",
              "      <th>624</th>\n",
              "      <th>625</th>\n",
              "      <th>626</th>\n",
              "      <th>627</th>\n",
              "      <th>628</th>\n",
              "      <th>629</th>\n",
              "      <th>630</th>\n",
              "      <th>631</th>\n",
              "      <th>632</th>\n",
              "      <th>633</th>\n",
              "      <th>634</th>\n",
              "      <th>635</th>\n",
              "      <th>636</th>\n",
              "      <th>637</th>\n",
              "      <th>638</th>\n",
              "      <th>639</th>\n",
              "      <th>640</th>\n",
              "      <th>641</th>\n",
              "      <th>642</th>\n",
              "      <th>643</th>\n",
              "      <th>644</th>\n",
              "      <th>645</th>\n",
              "      <th>646</th>\n",
              "      <th>647</th>\n",
              "      <th>648</th>\n",
              "      <th>649</th>\n",
              "      <th>650</th>\n",
              "      <th>651</th>\n",
              "      <th>652</th>\n",
              "      <th>653</th>\n",
              "      <th>654</th>\n",
              "      <th>655</th>\n",
              "      <th>656</th>\n",
              "      <th>657</th>\n",
              "      <th>658</th>\n",
              "      <th>659</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 660 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  ...  651  652  653  654  655  656  657  658  659\n",
              "0  0  0  0  1  0  1  1  1  1  ...    0    0    1    0    0    0    0    1    1\n",
              "1  1  1  1  0  1  0  0  0  0  ...    1    1    0    1    1    1    1    0    0\n",
              "\n",
              "[2 rows x 660 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXCE3Ps7pRKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a35dd820-bc51-42b1-80e1-523df9a28456"
      },
      "source": [
        "X_data = np.array(X_data)\n",
        "Y_data = np.array(Y_data)\n",
        "print(\"{}----{}\".format(X_data.shape,Y_data.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12288, 660)----(2, 660)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Vk0SIaGLk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''parameters are\n",
        "X = X_data\n",
        "Y = Y_data\n",
        "bsize = size of minibatch'''\n",
        "\n",
        "def random_mini_batch(X,Y,bsize):  \n",
        "  assert X.shape[1] == Y.shape[1]       \n",
        "  m = Y.shape[1]\n",
        "\n",
        "  perm = list(np.random.permutation(m))\n",
        "\n",
        "  X_shuff = X[:,perm]\n",
        "  Y_shuff = Y[:,perm].reshape((2,m))\n",
        "\n",
        "  min_batch_list = []\n",
        "\n",
        "  for i in range(0,m-bsize+1 , bsize):  \n",
        "    min_batch_list.append( ((X_shuff[:,i:i+bsize]),(Y_shuff[:,i:i+bsize])) )\n",
        "\n",
        "  if m%bsize:\n",
        "    min_batch_list.append(((X_shuff[:,m-bsize+2:]),(Y_shuff[:,m-bsize+2:])))\n",
        "\n",
        "  return min_batch_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4htWaGN04FP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "\n",
        "    X = tf.compat.v1.placeholder(tf.float32, shape=(n_x, None), name = \"X\")\n",
        "    Y = tf.compat.v1.placeholder(tf.float32, shape=(n_y, None), name = \"Y\")\n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CuG4scq049b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters():\n",
        "\n",
        "    tf.random.set_seed(1)        \n",
        "\n",
        "    initializer = tf.initializers.GlorotNormal(seed=1)\n",
        "    initializer2 = tf.zeros_initializer()\n",
        "\n",
        "    W1 = tf.Variable(initializer([25,12288],dtype=tf.float32),name=\"W1\")\n",
        "    b1 = tf.Variable(initializer2([25,1],dtype=tf.float32),name=\"b1\")\n",
        "\n",
        "    W2 = tf.Variable(initializer([12, 25],dtype=tf.float32),name=\"W2\")\n",
        "    b2 = tf.Variable(initializer2([12,1],dtype=tf.float32),name=\"b2\")\n",
        "\n",
        "    W3 = tf.Variable(initializer([2, 12],dtype=tf.float32),name=\"W3\")\n",
        "    b3 = tf.Variable(initializer2([2,1],dtype=tf.float32),name=\"b3\")\n",
        "\n",
        "\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2,\n",
        "                  \"W3\": W3,\n",
        "                  \"b3\": b3}\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsX4T-ei1EuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "9b327d3c-6709-4367-87f2-c93c67cb10f9"
      },
      "source": [
        "with tf.compat.v1.Session()  as sess:\n",
        "    parameters = initialize_parameters()\n",
        "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "    print(\"b2 = \" + str(parameters[\"b2\"]))\n",
        "    print(\"W3 = \" + str(parameters[\"W3\"]))\n",
        "    print(\"b3 = \" + str(parameters[\"b3\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W1 = <tf.Variable 'W1:0' shape=(25, 12288) dtype=float32>\n",
            "b1 = <tf.Variable 'b1:0' shape=(25, 1) dtype=float32>\n",
            "W2 = <tf.Variable 'W2:0' shape=(12, 25) dtype=float32>\n",
            "b2 = <tf.Variable 'b2:0' shape=(12, 1) dtype=float32>\n",
            "W3 = <tf.Variable 'W3:0' shape=(2, 12) dtype=float32>\n",
            "b3 = <tf.Variable 'b3:0' shape=(2, 1) dtype=float32>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRVY-idh1Hro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    \"\"\" LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\"\"\"\n",
        "    \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "    \n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)                      \n",
        "    A1 = tf.nn.relu(Z1)                                   \n",
        "    Z2 = tf.add(tf.matmul(W2, A1), b2)                    \n",
        "    A2 = tf.nn.relu(Z2)                                    \n",
        "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     \n",
        "\n",
        "    return Z3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWOMROVp1Q4O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d28f69c3-7a3d-4f5f-f87c-40023cc6120d"
      },
      "source": [
        "with tf.compat.v1.Session() as sess:\n",
        "    X, Y = create_placeholders(12288, 2)\n",
        "    parameters = initialize_parameters()\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    print(\"Z3 = \" + str(Z3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z3 = Tensor(\"Add_2:0\", shape=(2, None), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxPBZwpwRtrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(Z3, Y):\n",
        "\n",
        "    logits = tf.transpose(Z3)\n",
        "    labels = tf.transpose(Y)\n",
        "    \n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4rj97Wk5TsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X_data, Y_data,  learning_rate = 0.0001, num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
        "\n",
        "    '''n_x --> No. of rows in X_data    (in our case n_x = 64x64x3)\n",
        "       n_y --> No. of rows in Y_data    (in our case n_y = 2)\n",
        "       m   --> No. of examples          (in our case m = 660)\n",
        "    '''\n",
        "\n",
        "    ops.reset_default_graph()                         \n",
        "    tf.random.set_seed(1)                             \n",
        "    seed = 3 \n",
        "\n",
        "    tf.compat.v1.disable_eager_execution()\n",
        "                                                             \n",
        "    (n_x, m) = X_data.shape                          \n",
        "    n_y = Y_data.shape[0]                           \n",
        "    global costs                                      \n",
        "    \n",
        "    \n",
        "    #placeholders \n",
        "\n",
        "\n",
        "    X, Y = create_placeholders(n_x, n_y)       \n",
        "\n",
        "    parameters = initialize_parameters()\n",
        "\n",
        "\n",
        "    #the following two lines get stored in tenserflow graph and when the session runs these lines get executed.\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    cost = compute_cost(Z3, Y)  \n",
        "\n",
        "\n",
        "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)   #or we can use GradientDescentOptimizer()\n",
        "    \n",
        "    init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "\n",
        "    with tf.compat.v1.Session() as sess:\n",
        "        \n",
        "        sess.run(init)\n",
        "      \n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            epoch_cost = 0.                            #Defines a cost related to an epoch\n",
        "            num_minibatches = int(m / minibatch_size)  #number of minibatches of size minibatch_size in the train set\n",
        "            seed = seed + 1\n",
        "            minibatches = random_mini_batch(X_data, Y_data, minibatch_size)\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                          \n",
        "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
        "                             \n",
        "                epoch_cost += minibatch_cost / num_minibatches\n",
        "\n",
        "           \n",
        "            if print_cost == True and epoch % 100 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                costs.append(epoch_cost)\n",
        "\n",
        "        parameters = sess.run(parameters)\n",
        "        # Calculate the correct predictions\n",
        "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
        "\n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "        print (\"Train Accuracy:\", accuracy.eval({X: X_data, Y: Y_data}))\n",
        "          \n",
        "        \n",
        "        return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFQzLILsCUId",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "7027294a-e879-49b1-b844-d1ac69ad658a"
      },
      "source": [
        "costs = []\n",
        "trained_param = model(X_data,Y_data,0.001,1500,128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after epoch 0: 1.070055\n",
            "Cost after epoch 100: 0.004174\n",
            "Cost after epoch 200: 0.000821\n",
            "Cost after epoch 300: 0.000366\n",
            "Cost after epoch 400: 0.000149\n",
            "Cost after epoch 500: 0.000077\n",
            "Cost after epoch 600: 0.000048\n",
            "Cost after epoch 700: 0.000029\n",
            "Cost after epoch 800: 0.000019\n",
            "Cost after epoch 900: 0.000016\n",
            "Cost after epoch 1000: 0.000011\n",
            "Cost after epoch 1100: 0.000006\n",
            "Cost after epoch 1200: 0.000004\n",
            "Cost after epoch 1300: 0.000004\n",
            "Cost after epoch 1400: 0.000002\n",
            "Train Accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu815Nb7v9-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eaab59cf-9865-4bd3-86fa-e40e01b03412"
      },
      "source": [
        "trained_param[\"W1\"].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 12288)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HuiZ9fTCXYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ab721e56-43b7-4c5b-ecc6-2a2ec3ac7c38"
      },
      "source": [
        "plt.plot(np.squeeze(costs))\n",
        "plt.ylabel('cost')\n",
        "plt.xlabel('iterations (per tens)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVRMz7G0yJru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(img,params):\n",
        "  cvt = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "  rimg = cv2.resize(cvt,(64,64))\n",
        "  img_np_arr = np.array(rimg,dtype=\"float32\")\n",
        "  img_flat = img_np_arr.reshape(12288,1)\n",
        "  img_norm = img_flat/255\n",
        "  assert img_norm.shape == (12288,1)\n",
        "  predVal = forward_propagation(img_norm,params)\n",
        "  return predVal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ9p2kRRzkZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "47347a3a-a68a-40a2-cc37-b94991027466"
      },
      "source": [
        "img = cv2.imread(\"/content/sample_data/ZZZZZZZZK.jpg\")\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "  predVal = np.squeeze(sess.run(predict(img,trained_param)))\n",
        "  print(predVal)\n",
        "  if predVal[0]>predVal[1]:\n",
        "    print(\"not notes\")\n",
        "  else:\n",
        "    print(\"Notes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-17.339302   5.117368]\n",
            "Notes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qrbJitJ2glr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "afbc1b4e-2501-47c6-f359-cf8510093b08"
      },
      "source": [
        "type(trained_param)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv7V_lgQCc2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/sample_data/trained_params.npy',trained_param)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSAYArIxU2p6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2=np.load('/content/sample_data/trained_params.npy',allow_pickle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJR1jpbWc7hD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce339d4b-8011-403f-93c3-18a13f9b7cbc"
      },
      "source": [
        "data2[()]['b1'].shape        #access each parameter like this"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEuy9MdJhKKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cb9fa15-cfd8-47ba-fbfb-385aedf202bf"
      },
      "source": [
        "trained_param[\"b1\"].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkHQavrgXFDa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "ce2bd26f-6281-4535-f0f4-dcfd856dce5d"
      },
      "source": [
        "np.equal(data2[()]['W1'],trained_param[\"W1\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       ...,\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3J_yfb9XLNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}